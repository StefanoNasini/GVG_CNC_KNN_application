{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4fb57f",
   "metadata": {},
   "source": [
    "# Processing dataset for KNN and GVG-CNC\n",
    "We will be processing monk1, monk2, monk3, balance-scale, tic-tac-toe, car_evaluation, kr-vs-kp datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebb564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a dictionary to store all the dataset\n",
    "total_dataset = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02927b4",
   "metadata": {},
   "source": [
    "## Data preprocessing -- Monk1 to Monk3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9e7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    root\n",
    "except NameError:\n",
    "    root = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ac97c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Index',\n",
       " 'monks-1.test',\n",
       " 'monks-1.train',\n",
       " 'monks-2.test',\n",
       " 'monks-2.train',\n",
       " 'monks-3.test',\n",
       " 'monks-3.train',\n",
       " 'monks.names',\n",
       " 'thrun.comparison.dat',\n",
       " 'thrun.comparison.ps.Z',\n",
       " 'update']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory and inspect existing files\n",
    "os.chdir(os.path.join(root, \"monk\"))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de1dbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>2</th>\n",
       "      <th>2.1</th>\n",
       "      <th>data_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>data_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  0  1  1.1  1.2  1.3  2  2.1   data_4\n",
       "0         NaN  0  1    1    1    1  4    1   data_7\n",
       "1         NaN  0  1    1    1    2  1    1   data_9\n",
       "2         NaN  0  1    1    1    2  1    2  data_10\n",
       "3         NaN  0  1    1    1    2  2    1  data_11\n",
       "4         NaN  0  1    1    1    2  3    1  data_13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore data structure\n",
    "\n",
    "df = pd.read_csv('monks-2.train', delimiter=' ')\n",
    "df.head()\n",
    "\n",
    "# need to remove the first and last column\n",
    "# column \"1\" is label, 1.1 to 1.5 are features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c73d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all monk datasets\n",
    "\n",
    "names = [ 'monks-1.test',\n",
    " 'monks-1.train',\n",
    " 'monks-2.test',\n",
    " 'monks-2.train',\n",
    " 'monks-3.test',\n",
    " 'monks-3.train']\n",
    "\n",
    "# create a dictionary to store all the monk datasets\n",
    "monk_dict = dict(zip(names, names))\n",
    "\n",
    "\n",
    "# rename the variable names to a til f, then define a1-a5, ..., f1-f5 as dummy variables\n",
    "for name in names:\n",
    "    df = pd.read_csv(name, delimiter=' ')\n",
    "    df = df.iloc[:, range(1, 8)]\n",
    "    df.columns= ['label', 'a', 'b', 'c', 'd', 'e', 'f']\n",
    "    df['a1'] = df['a'] == 1\n",
    "    df['a2'] = df['a'] == 2\n",
    "    df['a3'] = df['a'] == 3\n",
    "    df['a4'] = df['a'] == 4\n",
    "    df['a5'] = df['a'] == 5\n",
    "    \n",
    "    df['b1'] = df['b'] == 1\n",
    "    df['b2'] = df['b'] == 2\n",
    "    df['b3'] = df['b'] == 3\n",
    "    df['b4'] = df['b'] == 4\n",
    "    df['b5'] = df['b'] == 5\n",
    "    \n",
    "    df['c1'] = df['c'] == 1\n",
    "    df['c2'] = df['c'] == 2\n",
    "    df['c3'] = df['c'] == 3\n",
    "    df['c4'] = df['c'] == 4\n",
    "    df['c5'] = df['c'] == 5\n",
    "    \n",
    "    df['d1'] = df['d'] == 1\n",
    "    df['d2'] = df['d'] == 2\n",
    "    df['d3'] = df['d'] == 3\n",
    "    df['d4'] = df['d'] == 4\n",
    "    df['d5'] = df['d'] == 5\n",
    "    \n",
    "    df['e1'] = df['e'] == 1\n",
    "    df['e2'] = df['e'] == 2\n",
    "    df['e3'] = df['e'] == 3\n",
    "    df['e4'] = df['e'] == 4\n",
    "    df['e5'] = df['e'] == 5\n",
    "    \n",
    "    df['f1'] = df['f'] == 1\n",
    "    df['f2'] = df['f'] == 2\n",
    "    df['f3'] = df['f'] == 3\n",
    "    df['f4'] = df['f'] == 4\n",
    "    df['f5'] = df['f'] == 5\n",
    "    \n",
    "    new_columns = \"label a1 a2 a3 a4 a5 b1 b2 b3 b4 b5 c1 c2 c3 c4 c5 d1 d2 d3 d4 d5 e1 e2 e3 e4 e5 f1 f2 f3 f4 f5\".split(' ')\n",
    "    new_columns = \"label a1 a2 b1 b2 c1 d1 d2 e1 e2 e3 f1\".split(' ')\n",
    "    df = df[new_columns]\n",
    "    monk_dict[name] = df\n",
    "    \n",
    "# # append monks into total dataset\n",
    "# total_dataset |= monk_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd37ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monks-1.test has 431 instances and 11 features.\n",
      "monks-1.train has 123 instances and 11 features.\n",
      "monks-2.test has 431 instances and 11 features.\n",
      "monks-2.train has 168 instances and 11 features.\n",
      "monks-3.test has 431 instances and 11 features.\n",
      "monks-3.train has 121 instances and 11 features.\n"
     ]
    }
   ],
   "source": [
    "# inspect the dimension of dummy-variable-ized dataset\n",
    "for name in names:\n",
    "    n_instances, n_features_ = monk_dict[name].shape\n",
    "#     print(monk_dict[name].sum())\n",
    "    print(f\"{name} has {n_instances} instances and {n_features_-1} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc42545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the train and test dataset together\n",
    "\n",
    "monk1 = pd.concat([monk_dict['monks-1.train'], monk_dict['monks-1.test']], axis=0)\n",
    "monk2 = pd.concat([monk_dict['monks-2.train'], monk_dict['monks-2.test']], axis=0)\n",
    "monk3 = pd.concat([monk_dict['monks-3.train'], monk_dict['monks-3.test']], axis=0)\n",
    "\n",
    "\n",
    "monk1.index= range(monk1.shape[0])\n",
    "monk2.index= range(monk2.shape[0])\n",
    "monk3.index= range(monk3.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820ba78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store them into total dataset\n",
    "total_dataset['monk1'] = monk1\n",
    "total_dataset['monk2'] = monk2\n",
    "total_dataset['monk3'] = monk3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8ae9f",
   "metadata": {},
   "source": [
    "## Data Preprocessing -- Balance_scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22882b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balance-scale.data', 'balance-scale.names', 'Index']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory and inspect files\n",
    "\n",
    "os.chdir(os.path.join(root, \"balance_scale\"))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55d4dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  1  1.1  1.2  1.3\n",
       "0  R  1    1    1    2\n",
       "1  R  1    1    1    3\n",
       "2  R  1    1    1    4\n",
       "3  R  1    1    1    5\n",
       "4  R  1    1    2    1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect data structure\n",
    "\n",
    "balance_scale = pd.read_csv(\"balance-scale.data\")\n",
    "balance_scale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ea32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ['R' 'L' 'B']\n",
      "a [1 2 3 4 5]\n",
      "b [1 2 3 4 5]\n",
      "c [1 2 3 4 5]\n",
      "d [2 3 4 5 1]\n"
     ]
    }
   ],
   "source": [
    "# observe possible values for each variable\n",
    "df = balance_scale\n",
    "df.columns=['label', 'a', 'b', 'c', 'd']\n",
    "for col in df.columns:\n",
    "    print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eff0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables named a1-a5, ..., d1-d5\n",
    "\n",
    "df['a1'] = df['a'] == 1\n",
    "df['a2'] = df['a'] == 2\n",
    "df['a3'] = df['a'] == 3\n",
    "df['a4'] = df['a'] == 4\n",
    "df['a5'] = df['a'] == 5\n",
    "\n",
    "df['b1'] = df['b'] == 1\n",
    "df['b2'] = df['b'] == 2\n",
    "df['b3'] = df['b'] == 3\n",
    "df['b4'] = df['b'] == 4\n",
    "df['b5'] = df['b'] == 5\n",
    "\n",
    "df['c1'] = df['c'] == 1\n",
    "df['c2'] = df['c'] == 2\n",
    "df['c3'] = df['c'] == 3\n",
    "df['c4'] = df['c'] == 4\n",
    "df['c5'] = df['c'] == 5\n",
    "\n",
    "df['d1'] = df['d'] == 1\n",
    "df['d2'] = df['d'] == 2\n",
    "df['d3'] = df['d'] == 3\n",
    "df['d4'] = df['d'] == 4\n",
    "df['d5'] = df['d'] == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7870c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B', 'L', 'R'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes are \"Balanced\" \"Left\" and \"Right\"\n",
    "set(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e692180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only newly created columns as a new dataframe\n",
    "new_columns= \"label a1 a2 a3 a4 b1 b2 b3 b4 c1 c2 c3 c4 d1 d2 d3 d4\".split(\" \")\n",
    "df = df[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "482518bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset, where target is such that \"B\" (stands for Balanced) ->1 and other case->0\n",
    "balance_scale_B = df.replace({'B':1, 'L':0, 'R':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c15c9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset, where target is such that \"L\" (stands for Left) ->1 and other case->0\n",
    "balance_scale_L = df.replace({'B':0, 'L':1, 'R':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65d1d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store them into total dataset\n",
    "total_dataset |= dict(balance_scale_B=balance_scale_B)\n",
    "total_dataset |= dict(balance_scale_L=balance_scale_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a64864c",
   "metadata": {},
   "source": [
    "## Data preprocessing -- tic-tac-toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2da25422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Index', 'tic-tac-toe.data', 'tic-tac-toe.names']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory and inspect files\n",
    "os.chdir(os.path.join(root, \"tic+tac+toe+endgame\"))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1798e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>x.1</th>\n",
       "      <th>x.2</th>\n",
       "      <th>x.3</th>\n",
       "      <th>o</th>\n",
       "      <th>o.1</th>\n",
       "      <th>x.4</th>\n",
       "      <th>o.2</th>\n",
       "      <th>o.3</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>957 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x x.1 x.2 x.3  o o.1 x.4 o.2 o.3  positive\n",
       "0    x   x   x   x  o   o   o   x   o  positive\n",
       "1    x   x   x   x  o   o   o   o   x  positive\n",
       "2    x   x   x   x  o   o   o   b   b  positive\n",
       "3    x   x   x   x  o   o   b   o   b  positive\n",
       "4    x   x   x   x  o   o   b   b   o  positive\n",
       "..  ..  ..  ..  .. ..  ..  ..  ..  ..       ...\n",
       "952  o   x   x   x  o   o   o   x   x  negative\n",
       "953  o   x   o   x  x   o   x   o   x  negative\n",
       "954  o   x   o   x  o   x   x   o   x  negative\n",
       "955  o   x   o   o  x   x   x   o   x  negative\n",
       "956  o   o   x   x  x   o   o   x   x  negative\n",
       "\n",
       "[957 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read and inspect data\n",
    "df = pd.read_csv(\"tic-tac-toe.data\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2991f8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b', 'o', 'x'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give columns meaningful names\n",
    "df = df[['positive', 'x', 'x.1', 'x.2', 'x.3', 'x.4', 'o', 'o.1', 'o.2', 'o.3']]\n",
    "tic = df\n",
    "df.columns = ['label', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "# check and found out that feature is not binary\n",
    "set(df['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fd4fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform features into binary. Knowing that each original feature represent a configuration in a cell out of 3x3 grid.\n",
    "# which can either take value 'o' or 'x' or 'nothing'. \n",
    "\n",
    "if df['label'][0] in ['positive', 'negative']:\n",
    "    df['label'] = df['label'] == 'positive'\n",
    "\n",
    "df['x1'] = df['1'] == 'x'\n",
    "df['x2'] = df['2'] == 'x'\n",
    "df['x3'] = df['3'] == 'x'\n",
    "\n",
    "df['x4'] = df['4'] == 'x'\n",
    "df['x5'] = df['5'] == 'x'\n",
    "df['x6'] = df['6'] == 'x'\n",
    "\n",
    "df['x7'] = df['7'] == 'x'\n",
    "df['x8'] = df['8'] == 'x'\n",
    "df['x9'] = df['9'] == 'x'\n",
    "\n",
    "\n",
    "df['o1'] = df['1'] == 'o'\n",
    "df['o2'] = df['2'] == 'o'\n",
    "df['o3'] = df['3'] == 'o'\n",
    "\n",
    "df['o4'] = df['4'] == 'o'\n",
    "df['o5'] = df['5'] == 'o'\n",
    "df['o6'] = df['6'] == 'o'\n",
    "\n",
    "df['o7'] = df['7'] == 'o'\n",
    "df['o8'] = df['8'] == 'o'\n",
    "df['o9'] = df['9'] == 'o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b1749fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select newly created variable and store into total dataset\n",
    "tic_bin = df[['label', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'o1', 'o2', 'o3', 'o4', 'o5', 'o6', 'o7', 'o8', 'o9']]\n",
    "total_dataset |= dict(tic_bin=tic_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecffde4",
   "metadata": {},
   "source": [
    "## Data preprocessing -- car_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "395c959b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car.c45-names', 'car.data', 'car.names']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory and inspect files\n",
    "\n",
    "os.chdir(os.path.join(root, 'car+evaluation'))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "899a581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and give meaningful names to each column\n",
    "df = pd.read_csv('car.data')\n",
    "df.columns=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'label']\n",
    "df = df[['label', 'buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32ac1f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ['unacc' 'acc' 'vgood' 'good']\n",
      "buying ['vhigh' 'high' 'med' 'low']\n",
      "maint ['vhigh' 'high' 'med' 'low']\n",
      "doors ['2' '3' '4' '5more']\n",
      "persons ['2' '4' 'more']\n",
      "lug_boot ['small' 'med' 'big']\n",
      "safety ['med' 'high' 'low']\n"
     ]
    }
   ],
   "source": [
    "# See for each variable, what are the possible values.\n",
    "for col in df.columns:\n",
    "    print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5206a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give each variable numerical encodings since they are all ordinal variables\n",
    "df['label'].replace({\"unacc\":0, \"acc\":1, \"vgood\":2, \"good\":3}, inplace=True)\n",
    "df['buying'].replace({'vhigh':3, 'high':2, 'med':1, 'low':0}, inplace=True)\n",
    "df['maint'].replace({'vhigh':3, 'high':2, 'med':1, 'low':0}, inplace=True)\n",
    "df['doors'].replace({'2':2, '3':3, '4':4, '5more':5}, inplace=True)\n",
    "df['persons'].replace({'2':2, '4':4, 'more':5}, inplace=True)\n",
    "df['lug_boot'].replace({'small':0, 'med':1, 'big':2}, inplace=True)\n",
    "df['safety'].replace({'med':1, 'high':2, 'low':0}, inplace=True)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf8260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary variables based on different thresholds\n",
    "df['labelvgood'] = df['label'] == 3\n",
    "df['labelgood'] = df['label'] >= 2\n",
    "df['labelacc'] = df['label'] >= 1\n",
    "\n",
    "df['buyingvhigh'] = df['buying'] == 3\n",
    "df['buyinghigh'] = df['buying'] >= 2\n",
    "df['buyingmed'] = df['buying'] >= 1\n",
    "\n",
    "df['maintvhigh'] = df['maint'] == 3\n",
    "df['mainthigh'] = df['maint'] >= 2\n",
    "df['maintmed'] = df['maint'] >= 1\n",
    "\n",
    "df[\"doors5\"] = df['doors'] >= 5\n",
    "df[\"doors4\"] = df['doors'] >= 4\n",
    "df[\"doors3\"] = df['doors'] >= 3\n",
    "\n",
    "df[\"persons5\"] = df['persons']>=5\n",
    "df[\"persons4\"] = df['persons']>=4\n",
    "\n",
    "df[\"lug_boot2\"] = df[\"lug_boot\"] >=2\n",
    "df[\"lug_boot1\"] = df[\"lug_boot\"] >=1\n",
    "\n",
    "df[\"safety2\"] = df[\"safety\"] >=2\n",
    "df[\"safety1\"] = df[\"safety\"] >=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2340484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select newly created features and make 3 datasets based on target labels\n",
    "features = ['buyingvhigh', 'buyinghigh', 'buyingmed', \n",
    "            'maintvhigh', 'mainthigh', 'maintmed',\n",
    "            \"doors5\", \"doors4\", \"doors3\",\n",
    "            \"persons5\", \"persons4\",\n",
    "            \"lug_boot2\", \"lug_boot1\",\n",
    "            \"safety2\", \"safety1\"]\n",
    "car_evaluation_vgood = df[[\"labelvgood\"]+features]\n",
    "car_evaluation_good = df[[\"labelgood\"]+features]\n",
    "car_evaluation_acc = df[[\"labelacc\"]+features]\n",
    "\n",
    "car_evaluation_vgood = car_evaluation_vgood.rename(columns={\"labelvgood\": \"label\"})\n",
    "car_evaluation_good = car_evaluation_good.rename(columns={\"labelgood\": \"label\"})\n",
    "car_evaluation_acc = car_evaluation_acc.rename(columns={\"labelacc\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9e24b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store them into total dataset\n",
    "total_dataset |= dict(car_evaluation_vgood=car_evaluation_vgood,\n",
    "                     car_evaluation_good=car_evaluation_good,\n",
    "                     car_evaluation_acc=car_evaluation_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c25d6",
   "metadata": {},
   "source": [
    "## Data preprocessing -- kr-vs-kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efd82dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kr-vs-kp_csv.csv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory and inspect files\n",
    "os.chdir(os.path.join(root, \"kr-vs-kp\"))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a375ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bkblk\n",
      "['f' 't']\n",
      "bknwy\n",
      "['f' 't']\n",
      "bkon8\n",
      "['f' 't']\n",
      "bkona\n",
      "['f' 't']\n",
      "bkspr\n",
      "['f' 't']\n",
      "bkxbq\n",
      "['f' 't']\n",
      "bkxcr\n",
      "['f' 't']\n",
      "bkxwp\n",
      "['f' 't']\n",
      "blxwp\n",
      "['f' 't']\n",
      "bxqsq\n",
      "['f' 't']\n",
      "cntxt\n",
      "['f' 't']\n",
      "dsopp\n",
      "['f' 't']\n",
      "dwipd\n",
      "['l' 'g']\n",
      "hdchk\n",
      "['f' 't']\n",
      "katri\n",
      "['n' 'w' 'b']\n",
      "mulch\n",
      "['f' 't']\n",
      "qxmsq\n",
      "['f' 't']\n",
      "r2ar8\n",
      "['t' 'f']\n",
      "reskd\n",
      "['f' 't']\n",
      "reskr\n",
      "['f' 't']\n",
      "rimmx\n",
      "['f' 't']\n",
      "rkxwp\n",
      "['f' 't']\n",
      "rxmsq\n",
      "['f' 't']\n",
      "simpl\n",
      "['f' 't']\n",
      "skach\n",
      "['f' 't']\n",
      "skewr\n",
      "['t' 'f']\n",
      "skrxp\n",
      "['f' 't']\n",
      "spcop\n",
      "['f' 't']\n",
      "stlmt\n",
      "['f' 't']\n",
      "thrsk\n",
      "['f' 't']\n",
      "wkcti\n",
      "['f' 't']\n",
      "wkna8\n",
      "['f' 't']\n",
      "wknck\n",
      "['f' 't']\n",
      "wkovl\n",
      "['t' 'f']\n",
      "wkpos\n",
      "['t' 'f']\n",
      "wtoeg\n",
      "['n' 't']\n",
      "class\n",
      "['won' 'nowin']\n"
     ]
    }
   ],
   "source": [
    "# read and insepct possible values for each columns to see if they are already binary, and what are current values\n",
    "df = pd.read_csv(\"kr-vs-kp_csv.csv\")\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(df[col].unique())\n",
    "    \n",
    "df['katri_n'] = df['katri'] == 'n'\n",
    "df['katri_b'] = df['katri'] == 'b' # binary-ize all features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be6e2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns so that the label is the first (index 0) appearing. \n",
    "new_columns = ['class', 'bkblk', 'bknwy', 'bkon8', 'bkona', 'bkspr', 'bkxbq', 'bkxcr', 'bkxwp', 'blxwp', 'bxqsq', 'cntxt', 'dsopp', 'dwipd', 'hdchk', 'mulch', 'qxmsq', 'r2ar8', 'reskd', 'reskr', 'rimmx', 'rkxwp', 'rxmsq', 'simpl', 'skach', 'skewr', 'skrxp', 'spcop', 'stlmt', 'thrsk', 'wkcti', 'wkna8', 'wknck', 'wkovl', 'wkpos', 'wtoeg', 'katri_n', 'katri_b']\n",
    "df = df[new_columns] # reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60d58f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the features to be 0 1 while making sure each column is treaty correctly\n",
    "df.replace({\"won\":1, \"nowin\":0, \"t\":0, \"f\":1}, inplace=True)\n",
    "df.replace({\"l\":0, \"g\":1, \"n\":1}, inplace=True)\n",
    "\n",
    "df.columns = ['label'] + list(df.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e5f6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store it into total dataset\n",
    "total_dataset['kr-vs-kp'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db7803",
   "metadata": {},
   "source": [
    "## Getting statistics for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e742d6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monk1': (554, 12),\n",
       " 'monk2': (599, 12),\n",
       " 'monk3': (552, 12),\n",
       " 'balance_scale_B': (624, 17),\n",
       " 'balance_scale_L': (624, 17),\n",
       " 'tic_bin': (957, 19),\n",
       " 'car_evaluation_vgood': (1727, 16),\n",
       " 'car_evaluation_good': (1727, 16),\n",
       " 'car_evaluation_acc': (1727, 16),\n",
       " 'kr-vs-kp': (3196, 38)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions = dict()\n",
    "for key, df in total_dataset.items():\n",
    "    dimensions[key] = df.shape\n",
    "dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f16668f",
   "metadata": {},
   "source": [
    "## Write the data down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bfd6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new directory (if not already existing) called df (stands for dataframe)\n",
    "os.chdir(root)\n",
    "if \"df\" not in os.listdir():\n",
    "    os.mkdir(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ec09103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write down data in csv format\n",
    "for (name, df) in total_dataset.items():\n",
    "    df.to_csv(os.path.join(root, \"df\", name+\".csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e9814",
   "metadata": {},
   "source": [
    "# Generating data for C++ code\n",
    "Need phi_file, v_predefined_file and w_file\n",
    "## phi_file\n",
    "For telling who are friends and who are enemies. K-nearest are friends and K' farthest are enemies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7cc0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the distance between instances, i.e. two given rows. Euclidien 2-distance squared is used. \n",
    "def distance(df, i, j):\n",
    "        dff = df.astype(int)\n",
    "        return sum((dff.iloc[i, 1:] - dff.iloc[j, 1:])**2)\n",
    "\n",
    "# For the instance in i-th row, calculate the distance of it with all the other instances.\n",
    "# Reorder the distances and pick the K-first and K-last instances. If equality, pick all the instances of the same distance.\n",
    "def find_K_neighbors(df, i, K=3):\n",
    "    distances = [(j, distance(df, i, j)) for j in range(df.shape[0])] # attention : (i, 0) will be inside\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # create a dictionary to count : how many instances, j, are at a given distance (to the anchor instance i) ? \n",
    "    counter = dict()\n",
    "    for (j, d) in distances:\n",
    "        try:\n",
    "            counter[d] += 1\n",
    "        except KeyError:\n",
    "            counter[d] = 1    \n",
    "    \n",
    "    # find nearest neighbors\n",
    "    # pick a distance d_from0 such that (j, d) with d<d_from0 counts more than K\n",
    "    d_from0 = 0 # we pick d<d_thr\n",
    "    count = 0\n",
    "    while count < K+1: # (i, 0) are in and we want to exclude this\n",
    "        try:\n",
    "            count += counter[d_from0]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        d_from0 += 1\n",
    "        \n",
    "    \n",
    "    # find farthest neighbors\n",
    "    # pick a distance d_tomax such that (j, d) with d > d_tomax counts more than K\n",
    "    d_tomax = max(d for (j, d) in distances)\n",
    "    count = 0\n",
    "    while count < K:\n",
    "        try:\n",
    "            count += counter[d_tomax]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        d_tomax -= 1\n",
    "        \n",
    "    \n",
    "    # return a list, in order of index number, of whether it is among K-nearest (1), or among K-farthest(2), or neither case(0).\n",
    "    phidata_list = []\n",
    "    for (j, d) in sorted(distances, key=lambda x:x[0]):\n",
    "#     for (j, d) in sorted(distances, key=lambda x:x[1]):\n",
    "        if j == i:\n",
    "            phidata_list.append(0) # no link with itself\n",
    "        elif d < d_from0:\n",
    "            phidata_list.append(1) # 1 for phiup\n",
    "        elif d > d_tomax:\n",
    "            phidata_list.append(2) # 2 for phidown\n",
    "        else:\n",
    "            phidata_list.append(0) # 0 for no link\n",
    "    \n",
    "    return phidata_list\n",
    "            \n",
    "\n",
    "    \n",
    "# find_K_neighbors(total_dataset['monk1'], 0, K = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b2ca11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk1_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# run the find_K_neighbors n times (n = df.shape[0] is the number of rows). Store the lists into a matrix, saved in csv.  \n",
    "def create_phifile(df, filename, K=3):\n",
    "    parent = os.path.dirname(filename)\n",
    "    if os.path.basename(filename) in os.listdir(parent):\n",
    "        print(f\"{os.path.basename(filename)} already existed. Finished.\")\n",
    "        return None\n",
    "    begin = time()\n",
    "    phifile = pd.DataFrame(index=range(df.shape[0]), columns=range(df.shape[0]))\n",
    "    for i in range(df.shape[0]):\n",
    "        phidata_list = find_K_neighbors(df, i, K)\n",
    "        phifile.iloc[i, :] = np.array(phidata_list)\n",
    "        if i%10 == 1:\n",
    "            current = time()\n",
    "            print(f\"{current-begin} sec passed, {i} instances processed, {df.shape[0]-i} instances left, ETA={(df.shape[0]-i)*(current-begin)/i} secs\")\n",
    "\n",
    "            \n",
    "    phifile.to_csv(filename, header=False, index=False, sep=' ')\n",
    "    return phifile\n",
    "\n",
    "create_phifile(total_dataset['monk1'], os.path.join(root, \"data2run\", \"monk1_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d467b851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk2_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset['monk2'], os.path.join(root, \"data2run\",\"monk2_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad4f89c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk3_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset['monk3'], os.path.join(root, \"data2run\", \"monk3_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "473f0747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance_scale_B_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"balance_scale_B\"], os.path.join(root, \"data2run\", \"balance_scale_B_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1305f8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance_scale_L_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"balance_scale_L\"], os.path.join(root, \"data2run\", \"balance_scale_L_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d6c2006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tic_bin_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"tic_bin\"], os.path.join(root, \"data2run\", \"tic_bin_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fb902e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_evaluation_vgood_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"car_evaluation_vgood\"], os.path.join(root, \"data2run\", \"car_evaluation_vgood_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8dc6c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_evaluation_good_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"car_evaluation_good\"], os.path.join(root, \"data2run\", \"car_evaluation_good_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3fa8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_evaluation_acc_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"car_evaluation_acc\"], os.path.join(root, \"data2run\", \"car_evaluation_acc_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5da561cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kr-vs-kp_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"kr-vs-kp\"], os.path.join(root, \"data2run\", \"kr-vs-kp_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9707c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk1_graph.txt already existed. Finished.\n",
      "The graph of monk1 has been processed.\n",
      "\n",
      "monk2_graph.txt already existed. Finished.\n",
      "The graph of monk2 has been processed.\n",
      "\n",
      "monk3_graph.txt already existed. Finished.\n",
      "The graph of monk3 has been processed.\n",
      "\n",
      "balance_scale_B_graph.txt already existed. Finished.\n",
      "The graph of balance_scale_B has been processed.\n",
      "\n",
      "balance_scale_L_graph.txt already existed. Finished.\n",
      "The graph of balance_scale_L has been processed.\n",
      "\n",
      "tic_bin_graph.txt already existed. Finished.\n",
      "The graph of tic_bin has been processed.\n",
      "\n",
      "car_evaluation_vgood_graph.txt already existed. Finished.\n",
      "The graph of car_evaluation_vgood has been processed.\n",
      "\n",
      "car_evaluation_good_graph.txt already existed. Finished.\n",
      "The graph of car_evaluation_good has been processed.\n",
      "\n",
      "car_evaluation_acc_graph.txt already existed. Finished.\n",
      "The graph of car_evaluation_acc has been processed.\n",
      "\n",
      "kr-vs-kp_graph.txt already existed. Finished.\n",
      "The graph of kr-vs-kp has been processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the graph file, i.e. the adjacency matrix of the (fully-connected) network, where each row is an instance.\n",
    "def create_graphfile(df, filename):\n",
    "    parent = os.path.dirname(filename)\n",
    "    if os.path.basename(filename) in os.listdir(parent):\n",
    "        print(f\"{os.path.basename(filename)} already existed. Finished.\")\n",
    "        return None\n",
    "    graphfile = pd.DataFrame(index=range(df.shape[0]), columns=range(df.shape[0]), dtype=np.int8)\n",
    "    graphfile.iloc[:, :] = 1\n",
    "    np.fill_diagonal(graphfile.values, 0)\n",
    "    graphfile.to_csv(filename, header=False, index=False, sep= ' ')\n",
    "    \n",
    "for data in total_dataset.keys():\n",
    "    create_graphfile(total_dataset[data], os.path.join(root, \"data2run\", f\"{data}_graph.txt\"))\n",
    "    print(f\"The graph of {data} has been processed.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2c6de67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk1_weight.txt already existed. Finished.\n",
      "The weight of monk1 has been processed.\n",
      "\n",
      "monk2_weight.txt already existed. Finished.\n",
      "The weight of monk2 has been processed.\n",
      "\n",
      "monk3_weight.txt already existed. Finished.\n",
      "The weight of monk3 has been processed.\n",
      "\n",
      "balance_scale_B_weight.txt already existed. Finished.\n",
      "The weight of balance_scale_B has been processed.\n",
      "\n",
      "balance_scale_L_weight.txt already existed. Finished.\n",
      "The weight of balance_scale_L has been processed.\n",
      "\n",
      "tic_bin_weight.txt already existed. Finished.\n",
      "The weight of tic_bin has been processed.\n",
      "\n",
      "car_evaluation_vgood_weight.txt already existed. Finished.\n",
      "The weight of car_evaluation_vgood has been processed.\n",
      "\n",
      "car_evaluation_good_weight.txt already existed. Finished.\n",
      "The weight of car_evaluation_good has been processed.\n",
      "\n",
      "car_evaluation_acc_weight.txt already existed. Finished.\n",
      "The weight of car_evaluation_acc has been processed.\n",
      "\n",
      "kr-vs-kp_weight.txt already existed. Finished.\n",
      "The weight of kr-vs-kp has been processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the weight file, i.e. the weighted adjacency matrix of the (fully-connected) network, where each row is an instance.\n",
    "def create_weightfile(df, filename):\n",
    "    parent = os.path.dirname(filename)\n",
    "    if os.path.basename(filename) in os.listdir(parent):\n",
    "        print(f\"{os.path.basename(filename)} already existed. Finished.\")\n",
    "        return None    \n",
    "    weightfile = pd.DataFrame(index=range(df.shape[0]), columns=range(df.shape[0]), dtype=np.int8)\n",
    "    weightfile.iloc[:, :] = 1\n",
    "    np.fill_diagonal(weightfile.values, 0)\n",
    "    weightfile.to_csv(filename, header=False, index=False, sep= ' ')\n",
    "    \n",
    "for data in total_dataset.keys():\n",
    "    create_weightfile(total_dataset[data], os.path.join(root, \"data2run\", f\"{data}_weight.txt\"))\n",
    "    print(f\"The weight of {data} has been processed.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c07e28b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk1_v_predefined.txt already existed. Finished.\n",
      "The predefined label of monk1 has been processed.\n",
      "\n",
      "monk2_v_predefined.txt already existed. Finished.\n",
      "The predefined label of monk2 has been processed.\n",
      "\n",
      "monk3_v_predefined.txt already existed. Finished.\n",
      "The predefined label of monk3 has been processed.\n",
      "\n",
      "balance_scale_B_v_predefined.txt already existed. Finished.\n",
      "The predefined label of balance_scale_B has been processed.\n",
      "\n",
      "balance_scale_L_v_predefined.txt already existed. Finished.\n",
      "The predefined label of balance_scale_L has been processed.\n",
      "\n",
      "tic_bin_v_predefined.txt already existed. Finished.\n",
      "The predefined label of tic_bin has been processed.\n",
      "\n",
      "car_evaluation_vgood_v_predefined.txt already existed. Finished.\n",
      "The predefined label of car_evaluation_vgood has been processed.\n",
      "\n",
      "car_evaluation_good_v_predefined.txt already existed. Finished.\n",
      "The predefined label of car_evaluation_good has been processed.\n",
      "\n",
      "car_evaluation_acc_v_predefined.txt already existed. Finished.\n",
      "The predefined label of car_evaluation_acc has been processed.\n",
      "\n",
      "kr-vs-kp_v_predefined.txt already existed. Finished.\n",
      "The predefined label of kr-vs-kp has been processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the predefined value for each IF (individual-feature) pair. \n",
    "# 1 : the IF pair is forced to select 1\n",
    "# 0 : the IF pair is forced to select 0\n",
    "# -1 :the IF pair is free to choose between 0 and 1\n",
    "\n",
    "def create_v_predefined(df, filename, percentage=0.2): # percentage of test data vs all data\n",
    "    parent = os.path.dirname(filename)\n",
    "    if os.path.basename(filename) in os.listdir(parent):\n",
    "        print(f\"{os.path.basename(filename)} already existed. Finished.\")\n",
    "        return None    \n",
    "    a = np.linspace(0, 1, df.shape[0])\n",
    "    a = a < 1-percentage  # create a bool array of length number of rows, beginning with 80% of 1's followed by 20% of 0's \n",
    "    a = pd.Series(a)\n",
    "    a = a.astype(np.int8)\n",
    "    a = (df['label'] * a)-1 + a # turns the beginning 80% into the same as df['label'] and remaining 20% all equals -1\n",
    "    a.to_csv(filename, header=False, index=False, sep=' ')\n",
    "    \n",
    "    \n",
    "for data in total_dataset.keys():\n",
    "    \n",
    "    v_predefined = create_v_predefined(\n",
    "        total_dataset[data], os.path.join(root, \"data2run\", f'{data}_v_predefined.txt'))\n",
    "    print(f\"The predefined label of {data} has been processed.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe2abc1",
   "metadata": {},
   "source": [
    "# KNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "20647695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "753a298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing monk dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4da6e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_train and df_test are your training and test DataFrames respectively\n",
    "\n",
    "# Load your data and separate features (X) and labels (y)\n",
    "\n",
    "def calculate_accuracy_train_test_KNN(df_train, df_test, K=5):\n",
    "\n",
    "    X_train = df_train.iloc[:, 1:]  # Features from second column onwards\n",
    "    y_train = df_train.iloc[:, 0]   # Labels - first column\n",
    "\n",
    "    X_test = df_test.iloc[:, 1:]    # Features from second column onwards\n",
    "    y_test = df_test.iloc[:, 0]     # Labels - first column\n",
    "\n",
    "    # Initialize KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=K)  # You can adjust the number of neighbors as needed\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def calculate_accuracy_split_KNN(df, test_size=0.3, K=5, random_state=42):\n",
    "\n",
    "    # Assuming df is your DataFrame with both features and labels\n",
    "\n",
    "    # Separate features (X) and labels (y)\n",
    "    X = df.iloc[:, 1:]  # Features from the second column onwards\n",
    "    y = df.iloc[:, 0]   # Labels - first column\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    # Adjust the test_size according to the percentage you want to allocate to the test set\n",
    "\n",
    "    # Initialize KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=K)  # You can adjust the number of neighbors as needed\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74c1522b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'monk_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonk1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m calculate_accuracy_split_KNN(\u001b[43mmonk_dataset\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonks-1.train\u001b[39m\u001b[38;5;124m'\u001b[39m], total_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonks-1.test\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonk2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m calculate_accuracy_split_KNN(total_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonks-2.train\u001b[39m\u001b[38;5;124m'\u001b[39m], total_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonks-2.test\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'monk_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"monk1\")\n",
    "calculate_accuracy_split_KNN(total_dataset['monks-1.train'], total_dataset['monks-1.test'])\n",
    "print(\"monk2\")\n",
    "calculate_accuracy_split_KNN(total_dataset['monks-2.train'], total_dataset['monks-2.test'])\n",
    "print(\"monk3\")\n",
    "calculate_accuracy_split_KNN(total_dataset['monks-3.train'], total_dataset['monks-3.test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8a896df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['monks-1.test', 'monks-1.train', 'monks-2.test', 'monks-2.train', 'monks-3.test', 'monks-3.train', 'balance_scale_B', 'balance_scale_L', 'tic_bin', 'car_evaluation_vgood', 'car_evaluation_good', 'car_evaluation_acc', 'kr-vs-kp'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16078c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "monk1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calculate_accuracy_split_KNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(key)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mcalculate_accuracy_split_KNN\u001b[49m(df, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m52\u001b[39m, K\u001b[38;5;241m=\u001b[39mK)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'calculate_accuracy_split_KNN' is not defined"
     ]
    }
   ],
   "source": [
    "for K in [3, 5, 7]:\n",
    "    print(K)\n",
    "    for key, df in total_dataset.items():\n",
    "        if key.startswith('monks'):\n",
    "            continue\n",
    "        print(key)\n",
    "        calculate_accuracy_split_KNN(df, random_state=52, K=K)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc87be18",
   "metadata": {},
   "source": [
    "## Test how KNN algorithm works\n",
    "I create my own function of prediction and compare with KNN classifier from sklearn package. \n",
    "\n",
    "Conclusion : every instance (except one, surprisingly) has the same result out of sklearn-KNN and custom-KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f050a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94fdf99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=43)\n",
    "\n",
    "# Initialize the KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3433e09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the three closest instances are of distance and of label : \n",
      "0.01999999999999995 of label  0\n",
      "0.020000000000000122 of label  0\n",
      "0.050000000000000086 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.020000000000000122 of label  0\n",
      "0.020000000000000122 of label  0\n",
      "0.05 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.020000000000000035 of label  2\n",
      "0.09999999999999983 of label  2\n",
      "0.1899999999999999 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.10999999999999988 of label  1\n",
      "0.1400000000000002 of label  1\n",
      "0.1499999999999999 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.27999999999999986 of label  2\n",
      "0.6499999999999992 of label  2\n",
      "0.6699999999999999 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.009999999999999929 of label  0\n",
      "0.020000000000000122 of label  0\n",
      "0.029999999999999964 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.10999999999999993 of label  2\n",
      "0.34 of label  2\n",
      "0.4499999999999996 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.15999999999999984 of label  1\n",
      "0.19000000000000034 of label  1\n",
      "0.40999999999999964 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.18999999999999995 of label  1\n",
      "0.18999999999999995 of label  1\n",
      "0.36 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.2099999999999999 of label  1\n",
      "0.9199999999999993 of label  1\n",
      "2.3000000000000007 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.04000000000000007 of label  0\n",
      "0.08999999999999972 of label  0\n",
      "0.08999999999999977 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.10000000000000014 of label  1\n",
      "0.2399999999999997 of label  1\n",
      "0.41999999999999976 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.37000000000000055 of label  2\n",
      "0.9400000000000006 of label  2\n",
      "1.04 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.04999999999999982 of label  0\n",
      "0.050000000000000086 of label  0\n",
      "0.09000000000000016 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.0399999999999999 of label  1\n",
      "0.15000000000000005 of label  1\n",
      "0.24000000000000032 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.04000000000000007 of label  1\n",
      "0.12 of label  1\n",
      "0.21000000000000027 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.30000000000000027 of label  0\n",
      "0.38000000000000034 of label  0\n",
      "0.43000000000000044 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.04000000000000014 of label  0\n",
      "0.09000000000000014 of label  0\n",
      "0.13000000000000012 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.2399999999999997 of label  2\n",
      "0.41 of label  2\n",
      "0.5299999999999996 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.1800000000000003 of label  2\n",
      "0.25999999999999995 of label  2\n",
      "0.4100000000000001 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.06999999999999992 of label  0\n",
      "0.07000000000000002 of label  0\n",
      "0.1100000000000001 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.04000000000000013 of label  0\n",
      "0.09000000000000014 of label  0\n",
      "0.13000000000000012 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.020000000000000035 of label  0\n",
      "0.08999999999999998 of label  0\n",
      "0.09999999999999983 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.33999999999999997 of label  2\n",
      "0.44000000000000034 of label  2\n",
      "0.6099999999999998 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.029999999999999964 of label  2\n",
      "0.06000000000000028 of label  2\n",
      "0.25000000000000033 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.8600000000000005 of label  2\n",
      "1.4899999999999993 of label  2\n",
      "1.8199999999999992 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.019999999999999903 of label  0\n",
      "0.030000000000000117 of label  0\n",
      "0.030000000000000117 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.030000000000000228 of label  1\n",
      "0.1 of label  1\n",
      "0.1400000000000005 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.02000000000000008 of label  0\n",
      "0.09000000000000002 of label  0\n",
      "0.09000000000000007 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.010000000000000106 of label  0\n",
      "0.08999999999999998 of label  0\n",
      "0.11999999999999988 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.020000000000000035 of label  1\n",
      "0.05 of label  1\n",
      "0.09000000000000007 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.019999999999999934 of label  0\n",
      "0.06 of label  0\n",
      "0.14 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.12999999999999998 of label  1\n",
      "0.8700000000000003 of label  1\n",
      "0.8999999999999999 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.52 of label  1\n",
      "0.81 of label  1\n",
      "2.060000000000001 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.3099999999999999 of label  2\n",
      "0.38999999999999996 of label  2\n",
      "0.6899999999999997 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.06000000000000001 of label  2\n",
      "0.06000000000000011 of label  2\n",
      "0.11000000000000015 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.07000000000000003 of label  1\n",
      "0.2700000000000005 of label  1\n",
      "0.4099999999999997 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.050000000000000176 of label  2\n",
      "0.07000000000000021 of label  2\n",
      "0.0899999999999999 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.35 of label  1\n",
      "0.35000000000000014 of label  1\n",
      "0.54 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.039999999999999716 of label  1\n",
      "0.18000000000000033 of label  1\n",
      "0.26999999999999996 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.05999999999999993 of label  1\n",
      "0.2899999999999998 of label  1\n",
      "0.5900000000000005 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.09999999999999974 of label  2\n",
      "0.10999999999999999 of label  2\n",
      "0.2299999999999995 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.09000000000000007 of label  1\n",
      "0.09000000000000007 of label  1\n",
      "0.3399999999999998 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.09999999999999999 of label  1\n",
      "0.1800000000000001 of label  2\n",
      "0.17000000000000015 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.20999999999999996 of label  0\n",
      "0.31999999999999984 of label  0\n",
      "0.36000000000000015 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.10999999999999993 of label  1\n",
      "0.13999999999999999 of label  1\n",
      "0.16999999999999996 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.07000000000000003 of label  1\n",
      "0.1800000000000003 of label  1\n",
      "0.26000000000000045 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.20000000000000007 of label  1\n",
      "0.6000000000000003 of label  1\n",
      "0.6900000000000002 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.020000000000000122 of label  1\n",
      "0.09999999999999987 of label  1\n",
      "0.7300000000000003 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.07000000000000013 of label  1\n",
      "0.18000000000000013 of label  1\n",
      "0.35 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.12999999999999962 of label  2\n",
      "0.1300000000000001 of label  2\n",
      "0.2600000000000001 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.06999999999999977 of label  1\n",
      "0.14000000000000024 of label  1\n",
      "0.15 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.08000000000000014 of label  1\n",
      "0.10000000000000026 of label  1\n",
      "0.13999999999999999 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.09999999999999974 of label  2\n",
      "0.10999999999999999 of label  2\n",
      "0.2299999999999995 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.09000000000000007 of label  0\n",
      "0.1300000000000001 of label  0\n",
      "0.14000000000000024 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.54 of label  1\n",
      "0.7699999999999996 of label  1\n",
      "1.2299999999999995 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.2899999999999999 of label  2\n",
      "0.46000000000000013 of label  2\n",
      "0.8299999999999995 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.049999999999999996 of label  0\n",
      "0.1 of label  0\n",
      "0.2400000000000001 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.10999999999999985 of label  2\n",
      "0.1699999999999996 of label  2\n",
      "0.17999999999999952 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.09000000000000007 of label  2\n",
      "0.1399999999999999 of label  2\n",
      "0.14999999999999983 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.06999999999999977 of label  1\n",
      "0.10000000000000019 of label  1\n",
      "0.10999999999999995 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.029999999999999985 of label  0\n",
      "0.050000000000000086 of label  0\n",
      "0.06999999999999998 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.010000000000000002 of label  0\n",
      "0.06999999999999984 of label  0\n",
      "0.10999999999999982 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.05999999999999993 of label  1\n",
      "0.18000000000000013 of label  1\n",
      "0.3699999999999998 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.15000000000000013 of label  2\n",
      "0.25000000000000017 of label  2\n",
      "0.2899999999999996 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.03000000000000005 of label  2\n",
      "0.1699999999999997 of label  2\n",
      "0.16999999999999987 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n",
      "found the three closest instances are of distance and of label : \n",
      "0.08999999999999982 of label  0\n",
      "0.1299999999999999 of label  0\n",
      "0.3000000000000001 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.10000000000000017 of label  0\n",
      "0.22999999999999987 of label  0\n",
      "0.46000000000000035 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.10999999999999993 of label  0\n",
      "0.13 of label  0\n",
      "0.15999999999999992 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.12000000000000002 of label  0\n",
      "0.15000000000000008 of label  0\n",
      "0.36000000000000065 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.0900000000000001 of label  0\n",
      "0.0900000000000001 of label  0\n",
      "0.09999999999999994 of label  0\n",
      "the label is predicted to be\n",
      "Mode: 0\n",
      "found the three closest instances are of distance and of label : \n",
      "0.14999999999999997 of label  1\n",
      "0.27000000000000013 of label  1\n",
      "0.2999999999999993 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.2900000000000001 of label  1\n",
      "0.4399999999999999 of label  2\n",
      "0.4999999999999994 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.020000000000000122 of label  1\n",
      "0.2100000000000002 of label  2\n",
      "0.23000000000000068 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n",
      "found the three closest instances are of distance and of label : \n",
      "0.010000000000000018 of label  2\n",
      "0.09000000000000008 of label  2\n",
      "0.19 of label  2\n",
      "the label is predicted to be\n",
      "Mode: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[72]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_predict(X_train, y_train, x_test):\n",
    "    def distance(quad1, quad2):\n",
    "        return sum((quad1[i]-quad2[i])**2 for i in range(4))\n",
    "    # find 3 closest\n",
    "    candidates = []\n",
    "    for index, x_train in enumerate(X_train):\n",
    "        new_distance = distance(x_train, x_test)\n",
    "        if len(candidates) < 3:\n",
    "            candidates.append(index)\n",
    "            continue\n",
    "        if new_distance < distance(X_train[candidates[0]], x_test):\n",
    "            candidates[0] = index\n",
    "        elif new_distance < distance(X_train[candidates[1]], x_test):\n",
    "            candidates[1] = index\n",
    "        elif new_distance < distance(X_train[candidates[2]], x_test):\n",
    "            candidates[2] = index\n",
    "    print(\"found the three closest instances are of distance and of label : \")\n",
    "    for i in range(3):\n",
    "        print(distance(x_test, X_train[candidates[i]]), \"of label \", y_train[candidates[i]])\n",
    "    print(\"the label is predicted to be\")\n",
    "    mode_value = statistics.mode([y_train[candidates[i]] for i in range(3)])\n",
    "    print(\"Mode:\", mode_value)\n",
    "    return mode_value\n",
    "        \n",
    "    \n",
    "wrong = []\n",
    "for i in range(len(y_pred)):\n",
    "    if my_predict(X_train, y_train, X_test[i]) == y_pred[i]:\n",
    "        pass\n",
    "    else:\n",
    "        \n",
    "        wrong.append(i)\n",
    "\n",
    "\n",
    "\n",
    "# my_predict(X_train, y_train, X_test[i])\n",
    "wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db791ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the three closest instances are of distance and of label : \n",
      "0.2900000000000001 of label  1\n",
      "0.4399999999999999 of label  2\n",
      "0.4999999999999994 of label  1\n",
      "the label is predicted to be\n",
      "Mode: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_predict(X_train, y_train, X_test[72])\n",
    "y_pred[72]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed821074",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
