{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4fb57f",
   "metadata": {},
   "source": [
    "# Processing dataset for KNN and GVG-CNC\n",
    "We will be preprocessing monk1, monk2, monk3, balance-scale, tic-tac-toe, car_evaluation, kr-vs-kp datasets.\n",
    "In order for C++ code of GVG-CNC model to run, graph_data, weight_data and v_predefined_data need to be generated in a txt format with blank instead of comma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebb564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a dictionary to store all the dataset\n",
    "total_dataset = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02927b4",
   "metadata": {},
   "source": [
    "## Data preprocessing -- Monk1 to Monk3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9e7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    root\n",
    "except NameError:\n",
    "    root = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ac97c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Index',\n",
       " 'monks-1.test',\n",
       " 'monks-1.train',\n",
       " 'monks-2.test',\n",
       " 'monks-2.train',\n",
       " 'monks-3.test',\n",
       " 'monks-3.train',\n",
       " 'monks.names',\n",
       " 'thrun.comparison.dat',\n",
       " 'thrun.comparison.ps.Z',\n",
       " 'update']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory and inspect existing files\n",
    "os.chdir(os.path.join(root, \"monk\"))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de1dbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>2</th>\n",
       "      <th>2.1</th>\n",
       "      <th>data_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>data_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  0  1  1.1  1.2  1.3  2  2.1   data_4\n",
       "0         NaN  0  1    1    1    1  4    1   data_7\n",
       "1         NaN  0  1    1    1    2  1    1   data_9\n",
       "2         NaN  0  1    1    1    2  1    2  data_10\n",
       "3         NaN  0  1    1    1    2  2    1  data_11\n",
       "4         NaN  0  1    1    1    2  3    1  data_13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore data structure\n",
    "\n",
    "df = pd.read_csv('monks-2.train', delimiter=' ')\n",
    "df.head()\n",
    "\n",
    "# need to remove the first and last column\n",
    "# column \"1\" is label, 1.1 to 1.5 are features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c73d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all monk datasets\n",
    "\n",
    "names = [ 'monks-1.test',\n",
    " 'monks-1.train',\n",
    " 'monks-2.test',\n",
    " 'monks-2.train',\n",
    " 'monks-3.test',\n",
    " 'monks-3.train']\n",
    "\n",
    "# create a dictionary to store all the monk datasets\n",
    "monk_dict = dict(zip(names, names))\n",
    "\n",
    "\n",
    "# rename the variable names to a til f, then define a1-a5, ..., f1-f5 as dummy variables\n",
    "for name in names:\n",
    "    df = pd.read_csv(name, delimiter=' ')\n",
    "    df = df.iloc[:, range(1, 8)]\n",
    "    df.columns= ['label', 'a', 'b', 'c', 'd', 'e', 'f']\n",
    "    df['a1'] = df['a'] == 1\n",
    "    df['a2'] = df['a'] == 2\n",
    "    df['a3'] = df['a'] == 3\n",
    "    df['a4'] = df['a'] == 4\n",
    "    df['a5'] = df['a'] == 5\n",
    "    \n",
    "    df['b1'] = df['b'] == 1\n",
    "    df['b2'] = df['b'] == 2\n",
    "    df['b3'] = df['b'] == 3\n",
    "    df['b4'] = df['b'] == 4\n",
    "    df['b5'] = df['b'] == 5\n",
    "    \n",
    "    df['c1'] = df['c'] == 1\n",
    "    df['c2'] = df['c'] == 2\n",
    "    df['c3'] = df['c'] == 3\n",
    "    df['c4'] = df['c'] == 4\n",
    "    df['c5'] = df['c'] == 5\n",
    "    \n",
    "    df['d1'] = df['d'] == 1\n",
    "    df['d2'] = df['d'] == 2\n",
    "    df['d3'] = df['d'] == 3\n",
    "    df['d4'] = df['d'] == 4\n",
    "    df['d5'] = df['d'] == 5\n",
    "    \n",
    "    df['e1'] = df['e'] == 1\n",
    "    df['e2'] = df['e'] == 2\n",
    "    df['e3'] = df['e'] == 3\n",
    "    df['e4'] = df['e'] == 4\n",
    "    df['e5'] = df['e'] == 5\n",
    "    \n",
    "    df['f1'] = df['f'] == 1\n",
    "    df['f2'] = df['f'] == 2\n",
    "    df['f3'] = df['f'] == 3\n",
    "    df['f4'] = df['f'] == 4\n",
    "    df['f5'] = df['f'] == 5\n",
    "    \n",
    "    new_columns = \"label a1 a2 a3 a4 a5 b1 b2 b3 b4 b5 c1 c2 c3 c4 c5 d1 d2 d3 d4 d5 e1 e2 e3 e4 e5 f1 f2 f3 f4 f5\".split(' ')\n",
    "    new_columns = \"label a1 a2 b1 b2 c1 d1 d2 e1 e2 e3 f1\".split(' ')\n",
    "    df = df[new_columns]\n",
    "    monk_dict[name] = df\n",
    "    \n",
    "# # append monks into total dataset\n",
    "# total_dataset |= monk_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd37ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monks-1.test has 431 instances and 11 features.\n",
      "monks-1.train has 123 instances and 11 features.\n",
      "monks-2.test has 431 instances and 11 features.\n",
      "monks-2.train has 168 instances and 11 features.\n",
      "monks-3.test has 431 instances and 11 features.\n",
      "monks-3.train has 121 instances and 11 features.\n"
     ]
    }
   ],
   "source": [
    "# inspect the dimension of dummy-variable-ized dataset\n",
    "for name in names:\n",
    "    n_instances, n_features_ = monk_dict[name].shape\n",
    "#     print(monk_dict[name].sum())\n",
    "    print(f\"{name} has {n_instances} instances and {n_features_-1} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc42545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the train and test dataset together\n",
    "\n",
    "monk1 = pd.concat([monk_dict['monks-1.train'], monk_dict['monks-1.test']], axis=0)\n",
    "monk2 = pd.concat([monk_dict['monks-2.train'], monk_dict['monks-2.test']], axis=0)\n",
    "monk3 = pd.concat([monk_dict['monks-3.train'], monk_dict['monks-3.test']], axis=0)\n",
    "\n",
    "\n",
    "monk1.index= range(monk1.shape[0])\n",
    "monk2.index= range(monk2.shape[0])\n",
    "monk3.index= range(monk3.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820ba78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store them into total dataset\n",
    "total_dataset['monk1'] = monk1\n",
    "total_dataset['monk2'] = monk2\n",
    "total_dataset['monk3'] = monk3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8ae9f",
   "metadata": {},
   "source": [
    "## Data Preprocessing -- Balance_scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22882b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balance-scale.data', 'balance-scale.names', 'Index']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory and inspect files\n",
    "\n",
    "os.chdir(os.path.join(root, \"balance_scale\"))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55d4dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  1  1.1  1.2  1.3\n",
       "0  R  1    1    1    2\n",
       "1  R  1    1    1    3\n",
       "2  R  1    1    1    4\n",
       "3  R  1    1    1    5\n",
       "4  R  1    1    2    1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect data structure\n",
    "\n",
    "balance_scale = pd.read_csv(\"balance-scale.data\")\n",
    "balance_scale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ea32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ['R' 'L' 'B']\n",
      "a [1 2 3 4 5]\n",
      "b [1 2 3 4 5]\n",
      "c [1 2 3 4 5]\n",
      "d [2 3 4 5 1]\n"
     ]
    }
   ],
   "source": [
    "# observe possible values for each variable\n",
    "df = balance_scale\n",
    "df.columns=['label', 'a', 'b', 'c', 'd']\n",
    "for col in df.columns:\n",
    "    print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eff0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables named a1-a5, ..., d1-d5\n",
    "\n",
    "df['a1'] = df['a'] == 1\n",
    "df['a2'] = df['a'] == 2\n",
    "df['a3'] = df['a'] == 3\n",
    "df['a4'] = df['a'] == 4\n",
    "df['a5'] = df['a'] == 5\n",
    "\n",
    "df['b1'] = df['b'] == 1\n",
    "df['b2'] = df['b'] == 2\n",
    "df['b3'] = df['b'] == 3\n",
    "df['b4'] = df['b'] == 4\n",
    "df['b5'] = df['b'] == 5\n",
    "\n",
    "df['c1'] = df['c'] == 1\n",
    "df['c2'] = df['c'] == 2\n",
    "df['c3'] = df['c'] == 3\n",
    "df['c4'] = df['c'] == 4\n",
    "df['c5'] = df['c'] == 5\n",
    "\n",
    "df['d1'] = df['d'] == 1\n",
    "df['d2'] = df['d'] == 2\n",
    "df['d3'] = df['d'] == 3\n",
    "df['d4'] = df['d'] == 4\n",
    "df['d5'] = df['d'] == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7870c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B', 'L', 'R'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes are \"Balanced\" \"Left\" and \"Right\"\n",
    "set(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e692180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only newly created columns as a new dataframe\n",
    "new_columns= \"label a1 a2 a3 a4 b1 b2 b3 b4 c1 c2 c3 c4 d1 d2 d3 d4\".split(\" \")\n",
    "df = df[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "482518bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset, where target is such that \"B\" (stands for Balanced) ->1 and other case->0\n",
    "balance_scale_B = df.replace({'B':1, 'L':0, 'R':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c15c9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset, where target is such that \"L\" (stands for Left) ->1 and other case->0\n",
    "balance_scale_L = df.replace({'B':0, 'L':1, 'R':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65d1d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store them into total dataset\n",
    "total_dataset |= dict(balance_scale_B=balance_scale_B)\n",
    "total_dataset |= dict(balance_scale_L=balance_scale_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a64864c",
   "metadata": {},
   "source": [
    "## Data preprocessing -- tic-tac-toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2da25422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Index', 'tic-tac-toe.data', 'tic-tac-toe.names']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory and inspect files\n",
    "os.chdir(os.path.join(root, \"tic+tac+toe+endgame\"))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1798e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>x.1</th>\n",
       "      <th>x.2</th>\n",
       "      <th>x.3</th>\n",
       "      <th>o</th>\n",
       "      <th>o.1</th>\n",
       "      <th>x.4</th>\n",
       "      <th>o.2</th>\n",
       "      <th>o.3</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>957 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x x.1 x.2 x.3  o o.1 x.4 o.2 o.3  positive\n",
       "0    x   x   x   x  o   o   o   x   o  positive\n",
       "1    x   x   x   x  o   o   o   o   x  positive\n",
       "2    x   x   x   x  o   o   o   b   b  positive\n",
       "3    x   x   x   x  o   o   b   o   b  positive\n",
       "4    x   x   x   x  o   o   b   b   o  positive\n",
       "..  ..  ..  ..  .. ..  ..  ..  ..  ..       ...\n",
       "952  o   x   x   x  o   o   o   x   x  negative\n",
       "953  o   x   o   x  x   o   x   o   x  negative\n",
       "954  o   x   o   x  o   x   x   o   x  negative\n",
       "955  o   x   o   o  x   x   x   o   x  negative\n",
       "956  o   o   x   x  x   o   o   x   x  negative\n",
       "\n",
       "[957 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read and inspect data\n",
    "df = pd.read_csv(\"tic-tac-toe.data\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2991f8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b', 'o', 'x'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give columns meaningful names\n",
    "df = df[['positive', 'x', 'x.1', 'x.2', 'x.3', 'x.4', 'o', 'o.1', 'o.2', 'o.3']]\n",
    "tic = df\n",
    "df.columns = ['label', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "# check and found out that feature is not binary\n",
    "set(df['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fd4fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform features into binary. Knowing that each original feature represent a configuration in a cell out of 3x3 grid.\n",
    "# which can either take value 'o' or 'x' or 'nothing'. \n",
    "\n",
    "if df['label'][0] in ['positive', 'negative']:\n",
    "    df['label'] = df['label'] == 'positive'\n",
    "\n",
    "df['x1'] = df['1'] == 'x'\n",
    "df['x2'] = df['2'] == 'x'\n",
    "df['x3'] = df['3'] == 'x'\n",
    "\n",
    "df['x4'] = df['4'] == 'x'\n",
    "df['x5'] = df['5'] == 'x'\n",
    "df['x6'] = df['6'] == 'x'\n",
    "\n",
    "df['x7'] = df['7'] == 'x'\n",
    "df['x8'] = df['8'] == 'x'\n",
    "df['x9'] = df['9'] == 'x'\n",
    "\n",
    "\n",
    "df['o1'] = df['1'] == 'o'\n",
    "df['o2'] = df['2'] == 'o'\n",
    "df['o3'] = df['3'] == 'o'\n",
    "\n",
    "df['o4'] = df['4'] == 'o'\n",
    "df['o5'] = df['5'] == 'o'\n",
    "df['o6'] = df['6'] == 'o'\n",
    "\n",
    "df['o7'] = df['7'] == 'o'\n",
    "df['o8'] = df['8'] == 'o'\n",
    "df['o9'] = df['9'] == 'o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b1749fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select newly created variable and store into total dataset\n",
    "tic_bin = df[['label', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'o1', 'o2', 'o3', 'o4', 'o5', 'o6', 'o7', 'o8', 'o9']]\n",
    "total_dataset |= dict(tic_bin=tic_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecffde4",
   "metadata": {},
   "source": [
    "## Data preprocessing -- car_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "395c959b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car.c45-names', 'car.data', 'car.names']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory and inspect files\n",
    "\n",
    "os.chdir(os.path.join(root, 'car+evaluation'))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "899a581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and give meaningful names to each column\n",
    "df = pd.read_csv('car.data')\n",
    "df.columns=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'label']\n",
    "df = df[['label', 'buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32ac1f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ['unacc' 'acc' 'vgood' 'good']\n",
      "buying ['vhigh' 'high' 'med' 'low']\n",
      "maint ['vhigh' 'high' 'med' 'low']\n",
      "doors ['2' '3' '4' '5more']\n",
      "persons ['2' '4' 'more']\n",
      "lug_boot ['small' 'med' 'big']\n",
      "safety ['med' 'high' 'low']\n"
     ]
    }
   ],
   "source": [
    "# See for each variable, what are the possible values.\n",
    "for col in df.columns:\n",
    "    print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5206a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give each variable numerical encodings since they are all ordinal variables\n",
    "df['label'].replace({\"unacc\":0, \"acc\":1, \"vgood\":2, \"good\":3}, inplace=True)\n",
    "df['buying'].replace({'vhigh':3, 'high':2, 'med':1, 'low':0}, inplace=True)\n",
    "df['maint'].replace({'vhigh':3, 'high':2, 'med':1, 'low':0}, inplace=True)\n",
    "df['doors'].replace({'2':2, '3':3, '4':4, '5more':5}, inplace=True)\n",
    "df['persons'].replace({'2':2, '4':4, 'more':5}, inplace=True)\n",
    "df['lug_boot'].replace({'small':0, 'med':1, 'big':2}, inplace=True)\n",
    "df['safety'].replace({'med':1, 'high':2, 'low':0}, inplace=True)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf8260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary variables based on different thresholds\n",
    "df['labelvgood'] = df['label'] == 3\n",
    "df['labelgood'] = df['label'] >= 2\n",
    "df['labelacc'] = df['label'] >= 1\n",
    "\n",
    "df['buyingvhigh'] = df['buying'] == 3\n",
    "df['buyinghigh'] = df['buying'] >= 2\n",
    "df['buyingmed'] = df['buying'] >= 1\n",
    "\n",
    "df['maintvhigh'] = df['maint'] == 3\n",
    "df['mainthigh'] = df['maint'] >= 2\n",
    "df['maintmed'] = df['maint'] >= 1\n",
    "\n",
    "df[\"doors5\"] = df['doors'] >= 5\n",
    "df[\"doors4\"] = df['doors'] >= 4\n",
    "df[\"doors3\"] = df['doors'] >= 3\n",
    "\n",
    "df[\"persons5\"] = df['persons']>=5\n",
    "df[\"persons4\"] = df['persons']>=4\n",
    "\n",
    "df[\"lug_boot2\"] = df[\"lug_boot\"] >=2\n",
    "df[\"lug_boot1\"] = df[\"lug_boot\"] >=1\n",
    "\n",
    "df[\"safety2\"] = df[\"safety\"] >=2\n",
    "df[\"safety1\"] = df[\"safety\"] >=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2340484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select newly created features and make 3 datasets based on target labels\n",
    "features = ['buyingvhigh', 'buyinghigh', 'buyingmed', \n",
    "            'maintvhigh', 'mainthigh', 'maintmed',\n",
    "            \"doors5\", \"doors4\", \"doors3\",\n",
    "            \"persons5\", \"persons4\",\n",
    "            \"lug_boot2\", \"lug_boot1\",\n",
    "            \"safety2\", \"safety1\"]\n",
    "car_evaluation_vgood = df[[\"labelvgood\"]+features]\n",
    "car_evaluation_good = df[[\"labelgood\"]+features]\n",
    "car_evaluation_acc = df[[\"labelacc\"]+features]\n",
    "\n",
    "car_evaluation_vgood = car_evaluation_vgood.rename(columns={\"labelvgood\": \"label\"})\n",
    "car_evaluation_good = car_evaluation_good.rename(columns={\"labelgood\": \"label\"})\n",
    "car_evaluation_acc = car_evaluation_acc.rename(columns={\"labelacc\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9e24b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store them into total dataset\n",
    "total_dataset |= dict(car_evaluation_vgood=car_evaluation_vgood,\n",
    "                     car_evaluation_good=car_evaluation_good,\n",
    "                     car_evaluation_acc=car_evaluation_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c25d6",
   "metadata": {},
   "source": [
    "## Data preprocessing -- kr-vs-kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efd82dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kr-vs-kp_csv.csv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory and inspect files\n",
    "os.chdir(os.path.join(root, \"kr-vs-kp\"))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a375ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bkblk\n",
      "['f' 't']\n",
      "bknwy\n",
      "['f' 't']\n",
      "bkon8\n",
      "['f' 't']\n",
      "bkona\n",
      "['f' 't']\n",
      "bkspr\n",
      "['f' 't']\n",
      "bkxbq\n",
      "['f' 't']\n",
      "bkxcr\n",
      "['f' 't']\n",
      "bkxwp\n",
      "['f' 't']\n",
      "blxwp\n",
      "['f' 't']\n",
      "bxqsq\n",
      "['f' 't']\n",
      "cntxt\n",
      "['f' 't']\n",
      "dsopp\n",
      "['f' 't']\n",
      "dwipd\n",
      "['l' 'g']\n",
      "hdchk\n",
      "['f' 't']\n",
      "katri\n",
      "['n' 'w' 'b']\n",
      "mulch\n",
      "['f' 't']\n",
      "qxmsq\n",
      "['f' 't']\n",
      "r2ar8\n",
      "['t' 'f']\n",
      "reskd\n",
      "['f' 't']\n",
      "reskr\n",
      "['f' 't']\n",
      "rimmx\n",
      "['f' 't']\n",
      "rkxwp\n",
      "['f' 't']\n",
      "rxmsq\n",
      "['f' 't']\n",
      "simpl\n",
      "['f' 't']\n",
      "skach\n",
      "['f' 't']\n",
      "skewr\n",
      "['t' 'f']\n",
      "skrxp\n",
      "['f' 't']\n",
      "spcop\n",
      "['f' 't']\n",
      "stlmt\n",
      "['f' 't']\n",
      "thrsk\n",
      "['f' 't']\n",
      "wkcti\n",
      "['f' 't']\n",
      "wkna8\n",
      "['f' 't']\n",
      "wknck\n",
      "['f' 't']\n",
      "wkovl\n",
      "['t' 'f']\n",
      "wkpos\n",
      "['t' 'f']\n",
      "wtoeg\n",
      "['n' 't']\n",
      "class\n",
      "['won' 'nowin']\n"
     ]
    }
   ],
   "source": [
    "# read and insepct possible values for each columns to see if they are already binary, and what are current values\n",
    "df = pd.read_csv(\"kr-vs-kp_csv.csv\")\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(df[col].unique())\n",
    "    \n",
    "df['katri_n'] = df['katri'] == 'n'\n",
    "df['katri_b'] = df['katri'] == 'b' # binary-ize all features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be6e2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns so that the label is the first (index 0) appearing. \n",
    "new_columns = ['class', 'bkblk', 'bknwy', 'bkon8', 'bkona', 'bkspr', 'bkxbq', 'bkxcr', 'bkxwp', 'blxwp', 'bxqsq', 'cntxt', 'dsopp', 'dwipd', 'hdchk', 'mulch', 'qxmsq', 'r2ar8', 'reskd', 'reskr', 'rimmx', 'rkxwp', 'rxmsq', 'simpl', 'skach', 'skewr', 'skrxp', 'spcop', 'stlmt', 'thrsk', 'wkcti', 'wkna8', 'wknck', 'wkovl', 'wkpos', 'wtoeg', 'katri_n', 'katri_b']\n",
    "df = df[new_columns] # reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60d58f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the features to be 0 1 while making sure each column is treaty correctly\n",
    "df.replace({\"won\":1, \"nowin\":0, \"t\":0, \"f\":1}, inplace=True)\n",
    "df.replace({\"l\":0, \"g\":1, \"n\":1}, inplace=True)\n",
    "\n",
    "df.columns = ['label'] + list(df.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e5f6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store it into total dataset\n",
    "total_dataset['kr-vs-kp'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db7803",
   "metadata": {},
   "source": [
    "## Getting statistics for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e742d6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monk1': (554, 12),\n",
       " 'monk2': (599, 12),\n",
       " 'monk3': (552, 12),\n",
       " 'balance_scale_B': (624, 17),\n",
       " 'balance_scale_L': (624, 17),\n",
       " 'tic_bin': (957, 19),\n",
       " 'car_evaluation_vgood': (1727, 16),\n",
       " 'car_evaluation_good': (1727, 16),\n",
       " 'car_evaluation_acc': (1727, 16),\n",
       " 'kr-vs-kp': (3196, 38)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions = dict()\n",
    "for key, df in total_dataset.items():\n",
    "    dimensions[key] = df.shape\n",
    "dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be9aabb",
   "metadata": {},
   "source": [
    "## Write the data down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "025b4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new directory (if not already existing) called df (stands for dataframe)\n",
    "os.chdir(root)\n",
    "if \"df\" not in os.listdir():\n",
    "    os.mkdir(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9257422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write down data in csv format\n",
    "for (name, df) in total_dataset.items():\n",
    "    df.to_csv(os.path.join(root, \"df\", name+\".csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e9814",
   "metadata": {},
   "source": [
    "# Generating data for C++ code\n",
    "Need phi_file, v_predefined_file and w_file\n",
    "## phi_file\n",
    "For telling who are friends and who are enemies. K-nearest are friends and K' farthest are enemies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7cc0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the distance between instances, i.e. two given rows. Euclidien 2-distance squared is used. \n",
    "def distance(df, i, j):\n",
    "        dff = df.astype(int)\n",
    "        return sum((dff.iloc[i, 1:] - dff.iloc[j, 1:])**2)\n",
    "\n",
    "# For the instance in i-th row, calculate the distance of it with all the other instances.\n",
    "# Reorder the distances and pick the K-first and K-last instances. If equality, pick all the instances of the same distance.\n",
    "def find_K_neighbors(df, i, K=3):\n",
    "    distances = [(j, distance(df, i, j)) for j in range(df.shape[0])] # attention : (i, 0) will be inside\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # create a dictionary to count : how many instances, j, are at a given distance (to the anchor instance i) ? \n",
    "    counter = dict()\n",
    "    for (j, d) in distances:\n",
    "        try:\n",
    "            counter[d] += 1\n",
    "        except KeyError:\n",
    "            counter[d] = 1    \n",
    "    \n",
    "    # find nearest neighbors\n",
    "    # pick a distance d_from0 such that (j, d) with d<d_from0 counts more than K\n",
    "    d_from0 = 0 # we pick d<d_thr\n",
    "    count = 0\n",
    "    while count < K+1: # (i, 0) are in and we want to exclude this\n",
    "        try:\n",
    "            count += counter[d_from0]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        d_from0 += 1\n",
    "        \n",
    "    \n",
    "    # find farthest neighbors\n",
    "    # pick a distance d_tomax such that (j, d) with d > d_tomax counts more than K\n",
    "    d_tomax = max(d for (j, d) in distances)\n",
    "    count = 0\n",
    "    while count < K:\n",
    "        try:\n",
    "            count += counter[d_tomax]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        d_tomax -= 1\n",
    "        \n",
    "    \n",
    "    # return a list, in order of index number, of whether it is among K-nearest (1), or among K-farthest(2), or neither case(0).\n",
    "    phidata_list = []\n",
    "    for (j, d) in sorted(distances, key=lambda x:x[0]):\n",
    "#     for (j, d) in sorted(distances, key=lambda x:x[1]):\n",
    "        if j == i:\n",
    "            phidata_list.append(0) # no link with itself\n",
    "        elif d < d_from0:\n",
    "            phidata_list.append(1) # 1 for phiup\n",
    "        elif d > d_tomax:\n",
    "            phidata_list.append(2) # 2 for phidown\n",
    "        else:\n",
    "            phidata_list.append(0) # 0 for no link\n",
    "    \n",
    "    return phidata_list\n",
    "            \n",
    "\n",
    "    \n",
    "# find_K_neighbors(total_dataset['monk1'], 0, K = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b2ca11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk1_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# run the find_K_neighbors n times (n = df.shape[0] is the number of rows). Store the lists into a matrix, saved in csv.  \n",
    "def create_phifile(df, filename, K=3):\n",
    "    parent = os.path.dirname(filename)\n",
    "    if os.path.basename(filename) in os.listdir(parent):\n",
    "        print(f\"{os.path.basename(filename)} already existed. Finished.\")\n",
    "        return None\n",
    "    begin = time()\n",
    "    phifile = pd.DataFrame(index=range(df.shape[0]), columns=range(df.shape[0]))\n",
    "    for i in range(df.shape[0]):\n",
    "        phidata_list = find_K_neighbors(df, i, K)\n",
    "        phifile.iloc[i, :] = np.array(phidata_list)\n",
    "        if i%10 == 1:\n",
    "            current = time()\n",
    "            print(f\"{current-begin} sec passed, {i} instances processed, {df.shape[0]-i} instances left, ETA={(df.shape[0]-i)*(current-begin)/i} secs\")\n",
    "\n",
    "            \n",
    "    phifile.to_csv(filename, header=False, index=False, sep=' ')\n",
    "    return phifile\n",
    "\n",
    "create_phifile(total_dataset['monk1'], os.path.join(root, \"data2run\", \"monk1_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85d56b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk2_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset['monk2'], os.path.join(root, \"data2run\",\"monk2_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bba83726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk3_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset['monk3'], os.path.join(root, \"data2run\", \"monk3_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2f6be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance_scale_B_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"balance_scale_B\"], os.path.join(root, \"data2run\", \"balance_scale_B_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c400b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance_scale_L_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"balance_scale_L\"], os.path.join(root, \"data2run\", \"balance_scale_L_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "498b9fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tic_bin_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"tic_bin\"], os.path.join(root, \"data2run\", \"tic_bin_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34640352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_evaluation_vgood_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"car_evaluation_vgood\"], os.path.join(root, \"data2run\", \"car_evaluation_vgood_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0333d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_evaluation_good_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"car_evaluation_good\"], os.path.join(root, \"data2run\", \"car_evaluation_good_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd8bcc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_evaluation_acc_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"car_evaluation_acc\"], os.path.join(root, \"data2run\", \"car_evaluation_acc_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fde70096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kr-vs-kp_phifile.csv already existed. Finished.\n"
     ]
    }
   ],
   "source": [
    "create_phifile(total_dataset[\"kr-vs-kp\"], os.path.join(root, \"data2run\", \"kr-vs-kp_phifile.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9707c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk1_graph.txt already existed. Finished.\n",
      "The graph of monk1 has been processed.\n",
      "\n",
      "monk2_graph.txt already existed. Finished.\n",
      "The graph of monk2 has been processed.\n",
      "\n",
      "monk3_graph.txt already existed. Finished.\n",
      "The graph of monk3 has been processed.\n",
      "\n",
      "balance_scale_B_graph.txt already existed. Finished.\n",
      "The graph of balance_scale_B has been processed.\n",
      "\n",
      "balance_scale_L_graph.txt already existed. Finished.\n",
      "The graph of balance_scale_L has been processed.\n",
      "\n",
      "tic_bin_graph.txt already existed. Finished.\n",
      "The graph of tic_bin has been processed.\n",
      "\n",
      "car_evaluation_vgood_graph.txt already existed. Finished.\n",
      "The graph of car_evaluation_vgood has been processed.\n",
      "\n",
      "car_evaluation_good_graph.txt already existed. Finished.\n",
      "The graph of car_evaluation_good has been processed.\n",
      "\n",
      "car_evaluation_acc_graph.txt already existed. Finished.\n",
      "The graph of car_evaluation_acc has been processed.\n",
      "\n",
      "kr-vs-kp_graph.txt already existed. Finished.\n",
      "The graph of kr-vs-kp has been processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the graph file, i.e. the adjacency matrix of the (fully-connected) network, where each row is an instance.\n",
    "def create_graphfile(df, filename):\n",
    "    parent = os.path.dirname(filename)\n",
    "    if os.path.basename(filename) in os.listdir(parent):\n",
    "        print(f\"{os.path.basename(filename)} already existed. Finished.\")\n",
    "        return None\n",
    "    graphfile = pd.DataFrame(index=range(df.shape[0]), columns=range(df.shape[0]), dtype=np.int8)\n",
    "    graphfile.iloc[:, :] = 1\n",
    "    np.fill_diagonal(graphfile.values, 0)\n",
    "    graphfile.to_csv(filename, header=False, index=False, sep= ' ')\n",
    "    \n",
    "for data in total_dataset.keys():\n",
    "    create_graphfile(total_dataset[data], os.path.join(root, \"data2run\", f\"{data}_graph.txt\"))\n",
    "    print(f\"The graph of {data} has been processed.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2c6de67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk1_weight.txt already existed. Finished.\n",
      "The weight of monk1 has been processed.\n",
      "\n",
      "monk2_weight.txt already existed. Finished.\n",
      "The weight of monk2 has been processed.\n",
      "\n",
      "monk3_weight.txt already existed. Finished.\n",
      "The weight of monk3 has been processed.\n",
      "\n",
      "balance_scale_B_weight.txt already existed. Finished.\n",
      "The weight of balance_scale_B has been processed.\n",
      "\n",
      "balance_scale_L_weight.txt already existed. Finished.\n",
      "The weight of balance_scale_L has been processed.\n",
      "\n",
      "tic_bin_weight.txt already existed. Finished.\n",
      "The weight of tic_bin has been processed.\n",
      "\n",
      "car_evaluation_vgood_weight.txt already existed. Finished.\n",
      "The weight of car_evaluation_vgood has been processed.\n",
      "\n",
      "car_evaluation_good_weight.txt already existed. Finished.\n",
      "The weight of car_evaluation_good has been processed.\n",
      "\n",
      "car_evaluation_acc_weight.txt already existed. Finished.\n",
      "The weight of car_evaluation_acc has been processed.\n",
      "\n",
      "kr-vs-kp_weight.txt already existed. Finished.\n",
      "The weight of kr-vs-kp has been processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the weight file, i.e. the weighted adjacency matrix of the (fully-connected) network, where each row is an instance.\n",
    "def create_weightfile(df, filename):\n",
    "    parent = os.path.dirname(filename)\n",
    "    if os.path.basename(filename) in os.listdir(parent):\n",
    "        print(f\"{os.path.basename(filename)} already existed. Finished.\")\n",
    "        return None    \n",
    "    weightfile = pd.DataFrame(index=range(df.shape[0]), columns=range(df.shape[0]), dtype=np.int8)\n",
    "    weightfile.iloc[:, :] = 1\n",
    "    np.fill_diagonal(weightfile.values, 0)\n",
    "    weightfile.to_csv(filename, header=False, index=False, sep= ' ')\n",
    "    \n",
    "for data in total_dataset.keys():\n",
    "    create_weightfile(total_dataset[data], os.path.join(root, \"data2run\", f\"{data}_weight.txt\"))\n",
    "    print(f\"The weight of {data} has been processed.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c07e28b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monk1_v_predefined.txt already existed. Finished.\n",
      "The predefined label of monk1 has been processed.\n",
      "\n",
      "monk2_v_predefined.txt already existed. Finished.\n",
      "The predefined label of monk2 has been processed.\n",
      "\n",
      "monk3_v_predefined.txt already existed. Finished.\n",
      "The predefined label of monk3 has been processed.\n",
      "\n",
      "balance_scale_B_v_predefined.txt already existed. Finished.\n",
      "The predefined label of balance_scale_B has been processed.\n",
      "\n",
      "balance_scale_L_v_predefined.txt already existed. Finished.\n",
      "The predefined label of balance_scale_L has been processed.\n",
      "\n",
      "tic_bin_v_predefined.txt already existed. Finished.\n",
      "The predefined label of tic_bin has been processed.\n",
      "\n",
      "car_evaluation_vgood_v_predefined.txt already existed. Finished.\n",
      "The predefined label of car_evaluation_vgood has been processed.\n",
      "\n",
      "car_evaluation_good_v_predefined.txt already existed. Finished.\n",
      "The predefined label of car_evaluation_good has been processed.\n",
      "\n",
      "car_evaluation_acc_v_predefined.txt already existed. Finished.\n",
      "The predefined label of car_evaluation_acc has been processed.\n",
      "\n",
      "kr-vs-kp_v_predefined.txt already existed. Finished.\n",
      "The predefined label of kr-vs-kp has been processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the predefined value for each IF (individual-feature) pair. \n",
    "# 1 : the IF pair is forced to select 1\n",
    "# 0 : the IF pair is forced to select 0\n",
    "# -1 :the IF pair is free to choose between 0 and 1\n",
    "\n",
    "def create_v_predefined(df, filename, percentage=0.2): # percentage of test data vs all data\n",
    "    parent = os.path.dirname(filename)\n",
    "    if os.path.basename(filename) in os.listdir(parent):\n",
    "        print(f\"{os.path.basename(filename)} already existed. Finished.\")\n",
    "        return None    \n",
    "    a = np.linspace(0, 1, df.shape[0])\n",
    "    a = a < 1-percentage  # create a bool array of length number of rows, beginning with 80% of 1's followed by 20% of 0's \n",
    "    a = pd.Series(a)\n",
    "    a = a.astype(np.int8)\n",
    "    a = (df['label'] * a)-1 + a # turns the beginning 80% into the same as df['label'] and remaining 20% all equals -1\n",
    "    a.to_csv(filename, header=False, index=False, sep=' ')\n",
    "    \n",
    "    \n",
    "for data in total_dataset.keys():\n",
    "    \n",
    "    v_predefined = create_v_predefined(\n",
    "        total_dataset[data], os.path.join(root, \"data2run\", f'{data}_v_predefined.txt'))\n",
    "    print(f\"The predefined label of {data} has been processed.\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
